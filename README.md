# Home_Sales

## Read the home_sales_revised.csv data in the starter code into a Spark DataFrame.
## Create a temporary table called home_sales.
## Do Data Analysis to answer the questions
## Cache my temporary table and Check if my temporary table is cached
## Using the cached data, run the query that filters out the view ratings with an average price of greater than or equal to $350,000. Determine the runtime and compare it to uncached runtime.
## Partition by the "date_built" field on the formatted parquet home sales data.
## Create a temporary table for the parquet data.
## Run the query that filters out the view ratings with an average price of greater than or equal to $350,000. Determine the runtime and compare it to uncached runtime.
## Uncache the home_sales temporary table and verify that the home_sales temporary table is uncached using PySpark




## References
Data for this dataset was generated by edX Boot Camps LLC, and is intended for educational purposes only.
